{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cmarquis/Documents/penn/penn-ml-challenge/venv/lib/python3.8/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/cmarquis/Documents/penn/penn-ml-challenge/venv/lib/python3.8/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/cmarquis/Documents/penn/penn-ml-challenge/venv/lib/python3.8/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/cmarquis/Documents/penn/penn-ml-challenge/venv/lib/python3.8/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/cmarquis/Documents/penn/penn-ml-challenge/venv/lib/python3.8/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/cmarquis/Documents/penn/penn-ml-challenge/venv/lib/python3.8/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout, LSTM, Activation, Dense\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.callbacks import EarlyStopping\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price_open</th>\n",
       "      <th>price_high</th>\n",
       "      <th>price_low</th>\n",
       "      <th>price_close</th>\n",
       "      <th>volume_traded</th>\n",
       "      <th>trades_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7165.72</td>\n",
       "      <td>7165.72</td>\n",
       "      <td>7165.71</td>\n",
       "      <td>7165.71</td>\n",
       "      <td>0.021841</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7168.30</td>\n",
       "      <td>7168.30</td>\n",
       "      <td>7168.30</td>\n",
       "      <td>7168.30</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7170.50</td>\n",
       "      <td>7170.50</td>\n",
       "      <td>7170.50</td>\n",
       "      <td>7170.50</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7169.20</td>\n",
       "      <td>7169.20</td>\n",
       "      <td>7169.20</td>\n",
       "      <td>7169.20</td>\n",
       "      <td>0.004000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7169.20</td>\n",
       "      <td>7169.20</td>\n",
       "      <td>7169.20</td>\n",
       "      <td>7169.20</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>7179.50</td>\n",
       "      <td>7179.50</td>\n",
       "      <td>7179.50</td>\n",
       "      <td>7179.50</td>\n",
       "      <td>0.013325</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>7181.67</td>\n",
       "      <td>7181.67</td>\n",
       "      <td>7181.67</td>\n",
       "      <td>7181.67</td>\n",
       "      <td>0.013364</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>7179.50</td>\n",
       "      <td>7179.50</td>\n",
       "      <td>7179.50</td>\n",
       "      <td>7179.50</td>\n",
       "      <td>0.001526</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>7182.12</td>\n",
       "      <td>7182.12</td>\n",
       "      <td>7182.12</td>\n",
       "      <td>7182.12</td>\n",
       "      <td>0.013437</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>7176.56</td>\n",
       "      <td>7176.56</td>\n",
       "      <td>7176.56</td>\n",
       "      <td>7176.56</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      price_open  price_high  price_low  price_close  volume_traded  \\\n",
       "0        7165.72     7165.72    7165.71      7165.71       0.021841   \n",
       "1        7168.30     7168.30    7168.30      7168.30       1.000000   \n",
       "2        7170.50     7170.50    7170.50      7170.50       0.002000   \n",
       "3        7169.20     7169.20    7169.20      7169.20       0.004000   \n",
       "4        7169.20     7169.20    7169.20      7169.20       0.002000   \n",
       "...          ...         ...        ...          ...            ...   \n",
       "9995     7179.50     7179.50    7179.50      7179.50       0.013325   \n",
       "9996     7181.67     7181.67    7181.67      7181.67       0.013364   \n",
       "9997     7179.50     7179.50    7179.50      7179.50       0.001526   \n",
       "9998     7182.12     7182.12    7182.12      7182.12       0.013437   \n",
       "9999     7176.56     7176.56    7176.56      7176.56       0.000010   \n",
       "\n",
       "      trades_count  \n",
       "0                2  \n",
       "1                2  \n",
       "2                1  \n",
       "3                2  \n",
       "4                1  \n",
       "...            ...  \n",
       "9995             1  \n",
       "9996             1  \n",
       "9997             1  \n",
       "9998             1  \n",
       "9999             1  \n",
       "\n",
       "[10000 rows x 6 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('bitcoin.csv').drop(['time_period_start', 'time_period_end', 'time_open', 'time_close'], axis=1)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lookback Window\n",
    "\n",
    "In order to capture the past as features, we create the below function. It takes as input some number of seconds to look back, defaulted to 60 seconds.\n",
    "\n",
    "Question: Is this a good feature set? Can you find a better one?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price_open</th>\n",
       "      <th>price_high</th>\n",
       "      <th>price_low</th>\n",
       "      <th>price_close</th>\n",
       "      <th>volume_traded</th>\n",
       "      <th>trades_count</th>\n",
       "      <th>price_open_-1</th>\n",
       "      <th>price_high_-1</th>\n",
       "      <th>price_low_-1</th>\n",
       "      <th>price_close_-1</th>\n",
       "      <th>...</th>\n",
       "      <th>price_low_-58</th>\n",
       "      <th>price_close_-58</th>\n",
       "      <th>volume_traded_-58</th>\n",
       "      <th>trades_count_-58</th>\n",
       "      <th>price_open_-59</th>\n",
       "      <th>price_high_-59</th>\n",
       "      <th>price_low_-59</th>\n",
       "      <th>price_close_-59</th>\n",
       "      <th>volume_traded_-59</th>\n",
       "      <th>trades_count_-59</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>7154.97</td>\n",
       "      <td>7154.97</td>\n",
       "      <td>7154.97</td>\n",
       "      <td>7154.97</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>7163.30</td>\n",
       "      <td>7163.30</td>\n",
       "      <td>7163.30</td>\n",
       "      <td>7163.30</td>\n",
       "      <td>...</td>\n",
       "      <td>7168.30</td>\n",
       "      <td>7168.30</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7165.72</td>\n",
       "      <td>7165.72</td>\n",
       "      <td>7165.71</td>\n",
       "      <td>7165.71</td>\n",
       "      <td>0.021841</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>7161.20</td>\n",
       "      <td>7163.40</td>\n",
       "      <td>7161.20</td>\n",
       "      <td>7163.40</td>\n",
       "      <td>0.015800</td>\n",
       "      <td>2</td>\n",
       "      <td>7154.97</td>\n",
       "      <td>7154.97</td>\n",
       "      <td>7154.97</td>\n",
       "      <td>7154.97</td>\n",
       "      <td>...</td>\n",
       "      <td>7170.50</td>\n",
       "      <td>7170.50</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7168.30</td>\n",
       "      <td>7168.30</td>\n",
       "      <td>7168.30</td>\n",
       "      <td>7168.30</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>7154.98</td>\n",
       "      <td>7154.98</td>\n",
       "      <td>7154.97</td>\n",
       "      <td>7154.98</td>\n",
       "      <td>0.038357</td>\n",
       "      <td>3</td>\n",
       "      <td>7161.20</td>\n",
       "      <td>7163.40</td>\n",
       "      <td>7161.20</td>\n",
       "      <td>7163.40</td>\n",
       "      <td>...</td>\n",
       "      <td>7169.20</td>\n",
       "      <td>7169.20</td>\n",
       "      <td>0.004000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7170.50</td>\n",
       "      <td>7170.50</td>\n",
       "      <td>7170.50</td>\n",
       "      <td>7170.50</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>7154.98</td>\n",
       "      <td>7154.98</td>\n",
       "      <td>7154.98</td>\n",
       "      <td>7154.98</td>\n",
       "      <td>0.032201</td>\n",
       "      <td>1</td>\n",
       "      <td>7154.98</td>\n",
       "      <td>7154.98</td>\n",
       "      <td>7154.97</td>\n",
       "      <td>7154.98</td>\n",
       "      <td>...</td>\n",
       "      <td>7169.20</td>\n",
       "      <td>7169.20</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7169.20</td>\n",
       "      <td>7169.20</td>\n",
       "      <td>7169.20</td>\n",
       "      <td>7169.20</td>\n",
       "      <td>0.004000</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>7154.97</td>\n",
       "      <td>7154.97</td>\n",
       "      <td>7154.97</td>\n",
       "      <td>7154.97</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>7154.98</td>\n",
       "      <td>7154.98</td>\n",
       "      <td>7154.98</td>\n",
       "      <td>7154.98</td>\n",
       "      <td>...</td>\n",
       "      <td>7165.72</td>\n",
       "      <td>7169.20</td>\n",
       "      <td>0.075433</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7169.20</td>\n",
       "      <td>7169.20</td>\n",
       "      <td>7169.20</td>\n",
       "      <td>7169.20</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>7179.50</td>\n",
       "      <td>7179.50</td>\n",
       "      <td>7179.50</td>\n",
       "      <td>7179.50</td>\n",
       "      <td>0.013325</td>\n",
       "      <td>1</td>\n",
       "      <td>7179.04</td>\n",
       "      <td>7179.04</td>\n",
       "      <td>7178.23</td>\n",
       "      <td>7178.23</td>\n",
       "      <td>...</td>\n",
       "      <td>7178.64</td>\n",
       "      <td>7178.64</td>\n",
       "      <td>0.006793</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7179.88</td>\n",
       "      <td>7179.88</td>\n",
       "      <td>7179.88</td>\n",
       "      <td>7179.88</td>\n",
       "      <td>0.009628</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>7181.67</td>\n",
       "      <td>7181.67</td>\n",
       "      <td>7181.67</td>\n",
       "      <td>7181.67</td>\n",
       "      <td>0.013364</td>\n",
       "      <td>1</td>\n",
       "      <td>7179.50</td>\n",
       "      <td>7179.50</td>\n",
       "      <td>7179.50</td>\n",
       "      <td>7179.50</td>\n",
       "      <td>...</td>\n",
       "      <td>7178.64</td>\n",
       "      <td>7178.64</td>\n",
       "      <td>0.001249</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7178.64</td>\n",
       "      <td>7178.64</td>\n",
       "      <td>7178.64</td>\n",
       "      <td>7178.64</td>\n",
       "      <td>0.006793</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>7179.50</td>\n",
       "      <td>7179.50</td>\n",
       "      <td>7179.50</td>\n",
       "      <td>7179.50</td>\n",
       "      <td>0.001526</td>\n",
       "      <td>1</td>\n",
       "      <td>7181.67</td>\n",
       "      <td>7181.67</td>\n",
       "      <td>7181.67</td>\n",
       "      <td>7181.67</td>\n",
       "      <td>...</td>\n",
       "      <td>7178.64</td>\n",
       "      <td>7178.64</td>\n",
       "      <td>0.068287</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7178.64</td>\n",
       "      <td>7178.64</td>\n",
       "      <td>7178.64</td>\n",
       "      <td>7178.64</td>\n",
       "      <td>0.001249</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>7182.12</td>\n",
       "      <td>7182.12</td>\n",
       "      <td>7182.12</td>\n",
       "      <td>7182.12</td>\n",
       "      <td>0.013437</td>\n",
       "      <td>1</td>\n",
       "      <td>7179.50</td>\n",
       "      <td>7179.50</td>\n",
       "      <td>7179.50</td>\n",
       "      <td>7179.50</td>\n",
       "      <td>...</td>\n",
       "      <td>7173.77</td>\n",
       "      <td>7173.77</td>\n",
       "      <td>0.008064</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7178.64</td>\n",
       "      <td>7178.64</td>\n",
       "      <td>7178.64</td>\n",
       "      <td>7178.64</td>\n",
       "      <td>0.068287</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>7176.56</td>\n",
       "      <td>7176.56</td>\n",
       "      <td>7176.56</td>\n",
       "      <td>7176.56</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>1</td>\n",
       "      <td>7182.12</td>\n",
       "      <td>7182.12</td>\n",
       "      <td>7182.12</td>\n",
       "      <td>7182.12</td>\n",
       "      <td>...</td>\n",
       "      <td>7173.77</td>\n",
       "      <td>7173.77</td>\n",
       "      <td>0.008074</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7173.77</td>\n",
       "      <td>7173.77</td>\n",
       "      <td>7173.77</td>\n",
       "      <td>7173.77</td>\n",
       "      <td>0.008064</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9941 rows × 360 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      price_open  price_high  price_low  price_close  volume_traded  \\\n",
       "59       7154.97     7154.97    7154.97      7154.97       2.000000   \n",
       "60       7161.20     7163.40    7161.20      7163.40       0.015800   \n",
       "61       7154.98     7154.98    7154.97      7154.98       0.038357   \n",
       "62       7154.98     7154.98    7154.98      7154.98       0.032201   \n",
       "63       7154.97     7154.97    7154.97      7154.97       2.000000   \n",
       "...          ...         ...        ...          ...            ...   \n",
       "9995     7179.50     7179.50    7179.50      7179.50       0.013325   \n",
       "9996     7181.67     7181.67    7181.67      7181.67       0.013364   \n",
       "9997     7179.50     7179.50    7179.50      7179.50       0.001526   \n",
       "9998     7182.12     7182.12    7182.12      7182.12       0.013437   \n",
       "9999     7176.56     7176.56    7176.56      7176.56       0.000010   \n",
       "\n",
       "      trades_count  price_open_-1  price_high_-1  price_low_-1  \\\n",
       "59               2        7163.30        7163.30       7163.30   \n",
       "60               2        7154.97        7154.97       7154.97   \n",
       "61               3        7161.20        7163.40       7161.20   \n",
       "62               1        7154.98        7154.98       7154.97   \n",
       "63               1        7154.98        7154.98       7154.98   \n",
       "...            ...            ...            ...           ...   \n",
       "9995             1        7179.04        7179.04       7178.23   \n",
       "9996             1        7179.50        7179.50       7179.50   \n",
       "9997             1        7181.67        7181.67       7181.67   \n",
       "9998             1        7179.50        7179.50       7179.50   \n",
       "9999             1        7182.12        7182.12       7182.12   \n",
       "\n",
       "      price_close_-1  ...  price_low_-58  price_close_-58  volume_traded_-58  \\\n",
       "59           7163.30  ...        7168.30          7168.30           1.000000   \n",
       "60           7154.97  ...        7170.50          7170.50           0.002000   \n",
       "61           7163.40  ...        7169.20          7169.20           0.004000   \n",
       "62           7154.98  ...        7169.20          7169.20           0.002000   \n",
       "63           7154.98  ...        7165.72          7169.20           0.075433   \n",
       "...              ...  ...            ...              ...                ...   \n",
       "9995         7178.23  ...        7178.64          7178.64           0.006793   \n",
       "9996         7179.50  ...        7178.64          7178.64           0.001249   \n",
       "9997         7181.67  ...        7178.64          7178.64           0.068287   \n",
       "9998         7179.50  ...        7173.77          7173.77           0.008064   \n",
       "9999         7182.12  ...        7173.77          7173.77           0.008074   \n",
       "\n",
       "      trades_count_-58  price_open_-59  price_high_-59  price_low_-59  \\\n",
       "59                 2.0         7165.72         7165.72        7165.71   \n",
       "60                 1.0         7168.30         7168.30        7168.30   \n",
       "61                 2.0         7170.50         7170.50        7170.50   \n",
       "62                 1.0         7169.20         7169.20        7169.20   \n",
       "63                 3.0         7169.20         7169.20        7169.20   \n",
       "...                ...             ...             ...            ...   \n",
       "9995               1.0         7179.88         7179.88        7179.88   \n",
       "9996               1.0         7178.64         7178.64        7178.64   \n",
       "9997               1.0         7178.64         7178.64        7178.64   \n",
       "9998               1.0         7178.64         7178.64        7178.64   \n",
       "9999               1.0         7173.77         7173.77        7173.77   \n",
       "\n",
       "      price_close_-59  volume_traded_-59  trades_count_-59  \n",
       "59            7165.71           0.021841               2.0  \n",
       "60            7168.30           1.000000               2.0  \n",
       "61            7170.50           0.002000               1.0  \n",
       "62            7169.20           0.004000               2.0  \n",
       "63            7169.20           0.002000               1.0  \n",
       "...               ...                ...               ...  \n",
       "9995          7179.88           0.009628               1.0  \n",
       "9996          7178.64           0.006793               1.0  \n",
       "9997          7178.64           0.001249               1.0  \n",
       "9998          7178.64           0.068287               1.0  \n",
       "9999          7173.77           0.008064               1.0  \n",
       "\n",
       "[9941 rows x 360 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def lookback(dataset, timesteps = 60):\n",
    "    # this uses the shift method of pandas dataframes to shift all of the columns down one row\n",
    "    # and then append to the original dataset\n",
    "    data = dataset\n",
    "    for i in range(1, timesteps):\n",
    "        step_back = dataset.shift(i).reset_index()\n",
    "        step_back.columns = ['index'] + [f'{column}_-{i}' for column in dataset.columns if column != 'index']\n",
    "        data = data.reset_index().merge(step_back, on='index', ).drop('index', axis=1)\n",
    "        \n",
    "    return data.dropna()\n",
    "        \n",
    "features = lookback(data)\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price_open</th>\n",
       "      <th>price_high</th>\n",
       "      <th>price_low</th>\n",
       "      <th>price_close</th>\n",
       "      <th>volume_traded</th>\n",
       "      <th>trades_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.267495</td>\n",
       "      <td>0.264047</td>\n",
       "      <td>0.339554</td>\n",
       "      <td>0.267368</td>\n",
       "      <td>3.358218e-04</td>\n",
       "      <td>0.011494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.300203</td>\n",
       "      <td>0.296333</td>\n",
       "      <td>0.369204</td>\n",
       "      <td>0.300203</td>\n",
       "      <td>1.538114e-02</td>\n",
       "      <td>0.011494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.328093</td>\n",
       "      <td>0.323864</td>\n",
       "      <td>0.394390</td>\n",
       "      <td>0.328093</td>\n",
       "      <td>3.063947e-05</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.311613</td>\n",
       "      <td>0.307596</td>\n",
       "      <td>0.379508</td>\n",
       "      <td>0.311613</td>\n",
       "      <td>6.140199e-05</td>\n",
       "      <td>0.011494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.311613</td>\n",
       "      <td>0.307596</td>\n",
       "      <td>0.379508</td>\n",
       "      <td>0.311613</td>\n",
       "      <td>3.063947e-05</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>0.442191</td>\n",
       "      <td>0.436491</td>\n",
       "      <td>0.497424</td>\n",
       "      <td>0.442191</td>\n",
       "      <td>2.048259e-04</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>0.469701</td>\n",
       "      <td>0.463647</td>\n",
       "      <td>0.522267</td>\n",
       "      <td>0.469701</td>\n",
       "      <td>2.054366e-04</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>0.442191</td>\n",
       "      <td>0.436491</td>\n",
       "      <td>0.497424</td>\n",
       "      <td>0.442191</td>\n",
       "      <td>2.334721e-05</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>0.475406</td>\n",
       "      <td>0.469278</td>\n",
       "      <td>0.527418</td>\n",
       "      <td>0.475406</td>\n",
       "      <td>2.065548e-04</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>0.404919</td>\n",
       "      <td>0.399700</td>\n",
       "      <td>0.463766</td>\n",
       "      <td>0.404919</td>\n",
       "      <td>3.076252e-08</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      price_open  price_high  price_low  price_close  volume_traded  \\\n",
       "0       0.267495    0.264047   0.339554     0.267368   3.358218e-04   \n",
       "1       0.300203    0.296333   0.369204     0.300203   1.538114e-02   \n",
       "2       0.328093    0.323864   0.394390     0.328093   3.063947e-05   \n",
       "3       0.311613    0.307596   0.379508     0.311613   6.140199e-05   \n",
       "4       0.311613    0.307596   0.379508     0.311613   3.063947e-05   \n",
       "...          ...         ...        ...          ...            ...   \n",
       "9995    0.442191    0.436491   0.497424     0.442191   2.048259e-04   \n",
       "9996    0.469701    0.463647   0.522267     0.469701   2.054366e-04   \n",
       "9997    0.442191    0.436491   0.497424     0.442191   2.334721e-05   \n",
       "9998    0.475406    0.469278   0.527418     0.475406   2.065548e-04   \n",
       "9999    0.404919    0.399700   0.463766     0.404919   3.076252e-08   \n",
       "\n",
       "      trades_count  \n",
       "0         0.011494  \n",
       "1         0.011494  \n",
       "2         0.000000  \n",
       "3         0.011494  \n",
       "4         0.000000  \n",
       "...            ...  \n",
       "9995      0.000000  \n",
       "9996      0.000000  \n",
       "9997      0.000000  \n",
       "9998      0.000000  \n",
       "9999      0.000000  \n",
       "\n",
       "[10000 rows x 6 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = MinMaxScaler()\n",
    "scaled_values = scaler.fit_transform(data.values)\n",
    "scaled_df = pd.DataFrame(scaled_values, index = data.index, columns = data.columns)\n",
    "scaled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9941, 359)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_in  = 60\n",
    "num_out = 1\n",
    "n_features = features.shape[1]\n",
    "\n",
    "# Splitting the data into appropriate sequences\n",
    "X, y = [], []\n",
    "    \n",
    "for i in range(len(s)):\n",
    "    end = i + n_steps_in\n",
    "    out_end = end + n_steps_out\n",
    "\n",
    "    if out_end > len(seq):\n",
    "        break\n",
    "\n",
    "    seq_x, seq_y = seq[i:end], seq[end:out_end]\n",
    "\n",
    "    X.append(seq_x)\n",
    "    y.append(seq_y)\n",
    "\n",
    "return np.array(X), np.array(y)\n",
    "X, y = split_sequence(list(df.Close), n_per_in, n_per_out)\n",
    "\n",
    "# Reshaping the X variable from 2D to 3D\n",
    "X = X.reshape((X.shape[0], X.shape[1], n_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "218/218 [==============================] - 0s 2ms/step - loss: 51482672.0000 - mean_squared_error: 51482672.0000 - mean_absolute_error: 7170.7412 - val_loss: 51821536.0000 - val_mean_squared_error: 51821536.0000 - val_mean_absolute_error: 7198.7134\n",
      "Epoch 2/20\n",
      "218/218 [==============================] - 0s 962us/step - loss: 51664692.0000 - mean_squared_error: 51664692.0000 - mean_absolute_error: 7187.7871 - val_loss: 51821536.0000 - val_mean_squared_error: 51821536.0000 - val_mean_absolute_error: 7198.7134\n",
      "Epoch 3/20\n",
      "218/218 [==============================] - 0s 1ms/step - loss: 51664704.0000 - mean_squared_error: 51664704.0000 - mean_absolute_error: 7187.7881 - val_loss: 51821536.0000 - val_mean_squared_error: 51821536.0000 - val_mean_absolute_error: 7198.7134\n",
      "Epoch 4/20\n",
      "218/218 [==============================] - 0s 1ms/step - loss: 51664696.0000 - mean_squared_error: 51664696.0000 - mean_absolute_error: 7187.7891 - val_loss: 51821536.0000 - val_mean_squared_error: 51821536.0000 - val_mean_absolute_error: 7198.7134\n",
      "Epoch 5/20\n",
      "218/218 [==============================] - 0s 1ms/step - loss: 51664700.0000 - mean_squared_error: 51664700.0000 - mean_absolute_error: 7187.7881 - val_loss: 51821536.0000 - val_mean_squared_error: 51821536.0000 - val_mean_absolute_error: 7198.7134\n",
      "Epoch 6/20\n",
      "218/218 [==============================] - 0s 968us/step - loss: 51664684.0000 - mean_squared_error: 51664684.0000 - mean_absolute_error: 7187.7861 - val_loss: 51821536.0000 - val_mean_squared_error: 51821536.0000 - val_mean_absolute_error: 7198.7134\n",
      "Epoch 7/20\n",
      "218/218 [==============================] - 0s 1ms/step - loss: 51664676.0000 - mean_squared_error: 51664676.0000 - mean_absolute_error: 7187.7871 - val_loss: 51821536.0000 - val_mean_squared_error: 51821536.0000 - val_mean_absolute_error: 7198.7134\n",
      "Epoch 8/20\n",
      "218/218 [==============================] - 0s 1ms/step - loss: 51664696.0000 - mean_squared_error: 51664696.0000 - mean_absolute_error: 7187.7866 - val_loss: 51821536.0000 - val_mean_squared_error: 51821536.0000 - val_mean_absolute_error: 7198.7134\n",
      "Epoch 9/20\n",
      "218/218 [==============================] - 0s 1ms/step - loss: 51664680.0000 - mean_squared_error: 51664680.0000 - mean_absolute_error: 7187.7881 - val_loss: 51821536.0000 - val_mean_squared_error: 51821536.0000 - val_mean_absolute_error: 7198.7134\n",
      "Epoch 10/20\n",
      "218/218 [==============================] - 0s 1ms/step - loss: 51664696.0000 - mean_squared_error: 51664696.0000 - mean_absolute_error: 7187.7842 - val_loss: 51821536.0000 - val_mean_squared_error: 51821536.0000 - val_mean_absolute_error: 7198.7134\n",
      "Epoch 11/20\n",
      "218/218 [==============================] - 0s 957us/step - loss: 51664700.0000 - mean_squared_error: 51664700.0000 - mean_absolute_error: 7187.7856 - val_loss: 51821536.0000 - val_mean_squared_error: 51821536.0000 - val_mean_absolute_error: 7198.7134\n",
      "Epoch 12/20\n",
      "218/218 [==============================] - 0s 1ms/step - loss: 51664684.0000 - mean_squared_error: 51664684.0000 - mean_absolute_error: 7187.7822 - val_loss: 51821536.0000 - val_mean_squared_error: 51821536.0000 - val_mean_absolute_error: 7198.7134\n",
      "Epoch 13/20\n",
      "218/218 [==============================] - 0s 1ms/step - loss: 51664692.0000 - mean_squared_error: 51664692.0000 - mean_absolute_error: 7187.7881 - val_loss: 51821536.0000 - val_mean_squared_error: 51821536.0000 - val_mean_absolute_error: 7198.7134\n",
      "Epoch 14/20\n",
      "218/218 [==============================] - 0s 1ms/step - loss: 51664676.0000 - mean_squared_error: 51664676.0000 - mean_absolute_error: 7187.7891 - val_loss: 51821536.0000 - val_mean_squared_error: 51821536.0000 - val_mean_absolute_error: 7198.7134\n",
      "Epoch 15/20\n",
      "218/218 [==============================] - 0s 1ms/step - loss: 51664700.0000 - mean_squared_error: 51664700.0000 - mean_absolute_error: 7187.7842 - val_loss: 51821536.0000 - val_mean_squared_error: 51821536.0000 - val_mean_absolute_error: 7198.7134\n",
      "Epoch 16/20\n",
      "218/218 [==============================] - 0s 955us/step - loss: 51664700.0000 - mean_squared_error: 51664700.0000 - mean_absolute_error: 7187.7861 - val_loss: 51821536.0000 - val_mean_squared_error: 51821536.0000 - val_mean_absolute_error: 7198.7134\n",
      "Epoch 17/20\n",
      "218/218 [==============================] - 0s 920us/step - loss: 51664692.0000 - mean_squared_error: 51664692.0000 - mean_absolute_error: 7187.7881 - val_loss: 51821536.0000 - val_mean_squared_error: 51821536.0000 - val_mean_absolute_error: 7198.7134\n",
      "Epoch 18/20\n",
      "218/218 [==============================] - 0s 1ms/step - loss: 51664696.0000 - mean_squared_error: 51664696.0000 - mean_absolute_error: 7187.7871 - val_loss: 51821536.0000 - val_mean_squared_error: 51821536.0000 - val_mean_absolute_error: 7198.7134\n",
      "Epoch 19/20\n",
      "218/218 [==============================] - 0s 1ms/step - loss: 51664696.0000 - mean_squared_error: 51664696.0000 - mean_absolute_error: 7187.7866 - val_loss: 51821536.0000 - val_mean_squared_error: 51821536.0000 - val_mean_absolute_error: 7198.7134\n",
      "Epoch 20/20\n",
      "218/218 [==============================] - 0s 999us/step - loss: 51664692.0000 - mean_squared_error: 51664692.0000 - mean_absolute_error: 7187.7871 - val_loss: 51821536.0000 - val_mean_squared_error: 51821536.0000 - val_mean_absolute_error: 7198.7134\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(32, input_dim=features.shape[1]))\n",
    "model.add(Dense(16))\n",
    "model.add(Dense(1, activation='relu'))\n",
    "\n",
    "model.compile(\n",
    "    loss='mse',\n",
    "    optimizer=Adam(lr=0.01), # is this the best optimizer/learning rate?\n",
    "    metrics=['mean_squared_error', 'mean_absolute_error'] # does accuracy make sense in this context?\n",
    ")\n",
    "\n",
    "## callbacks\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    mode='auto',\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "\n",
    "history = model.fit(\n",
    "    features,\n",
    "    target,\n",
    "    validation_split=.3,\n",
    "    epochs=20,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    /Users/cmarquis/Documents/penn/penn-ml-challenge/venv/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:571 train_function  *\n        outputs = self.distribute_strategy.run(\n    /Users/cmarquis/Documents/penn/penn-ml-challenge/venv/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:951 run  **\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /Users/cmarquis/Documents/penn/penn-ml-challenge/venv/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:2290 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /Users/cmarquis/Documents/penn/penn-ml-challenge/venv/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:2649 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /Users/cmarquis/Documents/penn/penn-ml-challenge/venv/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:531 train_step  **\n        y_pred = self(x, training=True)\n    /Users/cmarquis/Documents/penn/penn-ml-challenge/venv/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py:885 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs,\n    /Users/cmarquis/Documents/penn/penn-ml-challenge/venv/lib/python3.8/site-packages/tensorflow/python/keras/engine/input_spec.py:176 assert_input_compatibility\n        raise ValueError('Input ' + str(input_index) + ' of layer ' +\n\n    ValueError: Input 0 of layer sequential_2 is incompatible with the layer: expected ndim=3, found ndim=2. Full shape received: [None, 359]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-d5ab70526adf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# Using the training set to train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/penn/penn-ml-challenge/venv/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/penn/penn-ml-challenge/venv/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    846\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m    847\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 848\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    849\u001b[0m               \u001b[0;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m               \u001b[0;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/penn/penn-ml-challenge/venv/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/penn/penn-ml-challenge/venv/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    625\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    626\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 627\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    628\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/penn/penn-ml-challenge/venv/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    503\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_deleter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFunctionDeleter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lifted_initializer_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m     self._concrete_stateful_fn = (\n\u001b[0;32m--> 505\u001b[0;31m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    506\u001b[0m             *args, **kwds))\n\u001b[1;32m    507\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/penn/penn-ml-challenge/venv/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2444\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2445\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2446\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2447\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2448\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/penn/penn-ml-challenge/venv/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   2775\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2776\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2777\u001b[0;31m       \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2778\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2779\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/penn/penn-ml-challenge/venv/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   2655\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2656\u001b[0m     graph_function = ConcreteFunction(\n\u001b[0;32m-> 2657\u001b[0;31m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[1;32m   2658\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2659\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/penn/penn-ml-challenge/venv/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    979\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    980\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 981\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    982\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    983\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/penn/penn-ml-challenge/venv/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    439\u001b[0m         \u001b[0;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 441\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    442\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/penn/penn-ml-challenge/venv/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    966\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 968\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    969\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    970\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /Users/cmarquis/Documents/penn/penn-ml-challenge/venv/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:571 train_function  *\n        outputs = self.distribute_strategy.run(\n    /Users/cmarquis/Documents/penn/penn-ml-challenge/venv/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:951 run  **\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /Users/cmarquis/Documents/penn/penn-ml-challenge/venv/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:2290 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /Users/cmarquis/Documents/penn/penn-ml-challenge/venv/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:2649 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /Users/cmarquis/Documents/penn/penn-ml-challenge/venv/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:531 train_step  **\n        y_pred = self(x, training=True)\n    /Users/cmarquis/Documents/penn/penn-ml-challenge/venv/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py:885 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs,\n    /Users/cmarquis/Documents/penn/penn-ml-challenge/venv/lib/python3.8/site-packages/tensorflow/python/keras/engine/input_spec.py:176 assert_input_compatibility\n        raise ValueError('Input ' + str(input_index) + ' of layer ' +\n\n    ValueError: Input 0 of layer sequential_2 is incompatible with the layer: expected ndim=3, found ndim=2. Full shape received: [None, 359]\n"
     ]
    }
   ],
   "source": [
    "act_fun = 'sigmoid'\n",
    "\n",
    "# Initialize the RNN\n",
    "model = Sequential()\n",
    "\n",
    "# Adding the input layer and the LSTM layer\n",
    "model.add(LSTM(units = 30, activation=act_fun, return_sequences=True, input_shape=(None, features.shape[1])))\n",
    "\n",
    "# Adding the output layer\n",
    "model.add(Dense(units = 1))\n",
    "# Compiling the RNN\n",
    "model.compile(optimizer=Adam(lr=0.01), loss='mse', metrics=['mean_squared_error', 'mean_absolute_error'])\n",
    "\n",
    "# Using the training set to train the model\n",
    "model.fit(features, target, epochs = 100, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 32)                11520     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 12,065\n",
      "Trainable params: 12,065\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we calculate predictions and root mean square error. Can we easily improve this RMSE?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       ...,\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## prediction\n",
    "predictions = model.predict(features)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse = np.sqrt(np.mean(np.square((target.reshape(-1, 1) - predictions))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7191.088757578544"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Model\n",
    "\n",
    "The last thing we'll do is save the model for use in the API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
